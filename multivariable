Experiment 5 :

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# import warnings
import warnings
warnings.filterwarnings("ignore")
# We will use some methods from the sklearn module
from sklearn import linear_model
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split, cross_val_score
df = pd.read_csv("data.csv")
print(df.corr())
print(df.describe())
#Setting the value for X and Y
X = df[['Weight', 'Volume']]
y = df['CO2']
fig, axs = plt.subplots(2, figsize = (5,5))
plt1 = sns.boxplot(df['Weight'], ax = axs[0])
plt2 = sns.boxplot(df['Volume'], ax = axs[1])
plt.tight_layout()
sns.distplot(df['CO2']);
sns.pairplot(df, x_vars=['Weight', 'Volume'], y_vars='CO2', height=4, aspect=1, kind='scatter')
plt.show()
# Create the correlation matrix and represent it as a heatmap.
sns.heatmap(df.corr(), annot = True, cmap = 'coolwarm')
plt.show()
X_train,X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)
reg_model = linear_model.LinearRegression()
#Fitting the Multiple Linear Regression model
reg_model = LinearRegression().fit(X_train, y_train)
#Printing the model coefficients
print('Intercept: ',reg_model.intercept_)
# pair the feature names with the coefficients
list(zip(X, reg_model.coef_))
#Predicting the Test and Train set result
y_pred= reg_model.predict(X_test)
x_pred= reg_model.predict(X_train)
print("Prediction for test set: {}".format(y_pred))
#Actual value and the predicted value
reg_model_diff = pd.DataFrame({'Actual value': y_test, 'Predicted value': y_pred})
reg_model_diff
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
r2 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))
print('Mean Absolute Error:', mae)
print('Mean Square Error:', mse)
print('Root Mean Square Error:', r2)




Program 2 :
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model
from sklearn.model_selection import train_test_split
from sklearn import metrics
# Load the dataset
df = pd.read_csv("data.csv")
# Prepare the features and target variable
X = df[['Weight', 'Volume']]
y = df['CO2']
# Perform exploratory data analysis
print(df.corr())
sns.pairplot(df, x_vars=['Weight', 'Volume'], y_vars='CO2', height=4, aspect=1, kind='scatter')
plt.show()
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# Create and fit the multivariable regression model
reg_model = linear_model.LinearRegression()
reg_model.fit(X_train, y_train)
# Print model coefficients
print('Intercept:', reg_model.intercept_)
print('Coefficients:', reg_model.coef_)
# Make predictions
y_pred = reg_model.predict(X_test)
# Evaluate the model
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
r2 = metrics.r2_score(y_test, y_pred)
print('Mean Absolute Error:', mae)
print('Mean Squared Error:', mse)
print('R-squared:', r2)
# Visualize actual vs predicted values
plt.scatter(y_test, y_pred)
plt.xlabel('Actual CO2')
plt.ylabel('Predicted CO2')
plt.title('Actual vs Predicted CO2')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--') # 45-degree line
plt.show()
